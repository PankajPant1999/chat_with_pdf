{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYkNh3mL36fm",
    "outputId": "db7c398b-aaa2-407c-9693-e94286d8a815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting cohere\n",
      "  Downloading cohere-5.3.2-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
      "  Downloading fastavro-1.9.4-cp39-cp39-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from cohere) (0.26.0)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from cohere)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from cohere) (1.10.15)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from cohere) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.16.0,>=0.15.2 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from cohere) (0.15.2)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
      "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from cohere) (4.9.0)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (2021.10.8)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from httpx>=0.21.2->cohere) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (1.26.9)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from tokenizers<0.16.0,>=0.15.2->cohere) (0.22.2)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.0.0->cohere)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->cohere) (0.4.4)\n",
      "Downloading cohere-5.3.2-py3-none-any.whl (150 kB)\n",
      "   -------------------------------------- 150.3/150.3 kB 898.0 kB/s eta 0:00:00\n",
      "Downloading fastavro-1.9.4-cp39-cp39-win_amd64.whl (546 kB)\n",
      "   -------------------------------------- 546.3/546.3 kB 817.2 kB/s eta 0:00:00\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "   -------------------------------------- 121.1/121.1 kB 886.6 kB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, httpx-sse, fastavro, types-requests, cohere\n",
      "Successfully installed cohere-5.3.2 fastavro-1.9.4 httpx-sse-0.4.0 types-requests-2.31.0.20240406 urllib3-2.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  WARNING: The script fastavro.exe is installed in 'C:\\Users\\Pankaj Pant\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "tensorboard 2.11.0 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorflow-intel 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "botocore 1.24.32 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting annoy\n",
      "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
      "     ------------------------------------ 647.5/647.5 kB 948.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: annoy\n",
      "  Building wheel for annoy (setup.py): started\n",
      "  Building wheel for annoy (setup.py): finished with status 'done'\n",
      "  Created wheel for annoy: filename=annoy-1.17.3-cp39-cp39-win_amd64.whl size=53093 sha256=1f7ece73a511b91d9c4f43262860d14a18bb0e801459edb0ef1f4811f422be25\n",
      "  Stored in directory: c:\\users\\pankaj pant\\appdata\\local\\pip\\cache\\wheels\\09\\a9\\54\\37478e65995fe712f7da465749da9ddb21db6b1a599d591ac7\n",
      "Successfully built annoy\n",
      "Installing collected packages: annoy\n",
      "Successfully installed annoy-1.17.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install cohere\n",
    "!pip install annoy\n",
    "import cohere\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEPYwJcK8CVw",
    "outputId": "efdd6262-5302-4c47-da6a-3a2aa47b8503"
   },
   "outputs": [],
   "source": [
    "#question = \"What about your education?\"\n",
    "text = \"\"\n",
    "with open('story.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wPhY9uEt8NkS"
   },
   "outputs": [],
   "source": [
    "texts = text.split('\\n\\n')\n",
    "# Clean up to remove empty spaces and new lines\n",
    "texts = np.array([t.strip(' \\n') for t in texts if t])\n",
    "\n",
    "co = cohere.Client('yF0ryoncYMB6rlHQZybJNn9urUVfO1yx38svAuP9')\n",
    "\n",
    "# Get the embeddings\n",
    "response = co.embed(\n",
    "\n",
    "    texts=texts.tolist(),\n",
    "\n",
    ").embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUvFKUhX8h4S",
    "outputId": "bf73e17d-5b1f-44df-c52e-0a864585f26a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of the embeddings\n",
    "embeds = np.array(response)\n",
    "# Create the search index, pass the size of embedding\n",
    "search_index = AnnoyIndex(embeds.shape[1], 'angular')\n",
    "\n",
    "# Add all the vectors to the search index\n",
    "\n",
    "for i in range(len(embeds)):\n",
    "    search_index.add_item(i, embeds[i])\n",
    "\n",
    "search_index.build(10) # 10 trees\n",
    "search_index.save('test.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "svdSaa4s8pWL"
   },
   "outputs": [],
   "source": [
    "def search_text(query):\n",
    "    # Get the query's embedding\n",
    "    query_embed = co.embed(texts=[query]).embeddings\n",
    "    # Retrieve the nearest neighbors\n",
    "    similar_item_ids = search_index.get_nns_by_vector(query_embed[0],\n",
    "                                                    10,\n",
    "                                                  include_distances=True)\n",
    "\n",
    "    search_results = texts[similar_item_ids[0]]\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RQ11XbSV8wdI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bcrB244GCGfT"
   },
   "outputs": [],
   "source": [
    "def ask_llm(question, num_generations=1):\n",
    "    # Search the text archive\n",
    "    results = search_text(question)\n",
    "    # Get the top result\n",
    "    context = results[0]\n",
    "    # Prepare the prompt\n",
    "    prompt = f\"\"\"\n",
    "    More information about Australian beaches at australia.com:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Extract the answer of the question from the text provided.\n",
    "    If the text doesn't contain the answer,\n",
    "\n",
    "    reply that the answer is not available.\"\"\"\n",
    "\n",
    "    prediction = co.generate(\n",
    "        prompt=prompt,\n",
    "        max_tokens=70,\n",
    "        model=\"command-nightly\",\n",
    "        temperature=0.5,\n",
    "        num_generations=num_generations\n",
    "    )\n",
    "\n",
    "    return prediction.generations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLa_aOJwvqC_",
    "outputId": "41d4b1c9-c922-403d-9342-e23732f165fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The crocodile wanted to eat the monkey's heart.\n"
     ]
    }
   ],
   "source": [
    "question = \"what cocodile want\"\n",
    "results = ask_llm(question)\n",
    "print(results[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbZBnsofF89B",
    "outputId": "a33b4912-f640-4c6f-f2f1-ae81366486a1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gnbW2XEtGhAZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tEAlFL0TMh2P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "COGWlqbgCUC5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzyRTWguLnjz",
    "outputId": "39f6c78f-12d1-4939-8f4c-bae8905cc870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (2.90)\n",
      "Requirement already satisfied: comtypes in c:\\programdata\\anaconda3\\lib\\site-packages (from pyttsx3) (1.1.10)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyttsx3) (302)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: speechrecognition in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (3.8.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "'apt' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyaudio in c:\\users\\pankaj pant\\appdata\\roaming\\python\\python39\\site-packages (0.2.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3\n",
    "!pip install speechrecognition\n",
    "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "OGj3YzKpHgK_",
    "outputId": "bf4a50ec-3fb5-4ee5-93d3-8af36e025ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------speak-----\n",
      "unknown error occurred\n",
      "------speak-----\n",
      "unknown error occurred\n",
      "------speak-----\n",
      "unknown error occurred\n",
      "------speak-----\n",
      "unknown error occurred\n",
      "------speak-----\n",
      "Request  :  where crocodile live\n",
      "Response :  The crocodile lived in the river Ganges.\n",
      "------speak-----\n",
      "Request  :  what crocodile wife want\n",
      "Response :  The crocodile's wife wants to eat the monkey's heart.\n",
      "------speak-----\n",
      "Request  :  where monkey live\n",
      "Response :  The monkey lived in a big jamun tree.\n",
      "------speak-----\n",
      "Request  :  where is the jamun tree\n",
      "Response :  The jamun tree is on the bank of the river Ganges.\n",
      "------speak-----\n",
      "Request  :  what is the moral of story\n",
      "Response :  The moral of the story is that one should not be naive and trust others too easily, as even friends can have ulterior motives and deceive you.\n",
      "------speak-----\n",
      "Request  :  who is sourav\n",
      "Response :  The answer is not available.\n",
      "------speak-----\n",
      "Request  :  correct exit\n",
      "Response :  The answer is not available.\n",
      "------speak-----\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "# Initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Function to convert text to\n",
    "# speech\n",
    "def SpeakText(command):\n",
    "    # Initialize the engine\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "\n",
    "while(1):\n",
    "    try:\n",
    "        print(\"------speak-----\")\n",
    "        with sr.Microphone() as source2:\n",
    "            r.adjust_for_ambient_noise(source2, duration=0.2)\n",
    "            audio2 = r.listen(source2)\n",
    "\n",
    "            # Using google to recognize audio\n",
    "            question = r.recognize_google(audio2)\n",
    "            question = question.lower()\n",
    "            if question==\"exit\":\n",
    "                break\n",
    "            results = ask_llm(question)\n",
    "            answer = results[0].text\n",
    "\n",
    "            print(\"Request  : \",question)\n",
    "            print(\"Response : \",answer)\n",
    "\n",
    "            SpeakText(answer)\n",
    "\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results; {0}\".format(e))\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"unknown error occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4wrGiXM4FTzj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nBWi2doHMvQg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fD99SXQ0q2XI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhSkSxqoXs5t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
